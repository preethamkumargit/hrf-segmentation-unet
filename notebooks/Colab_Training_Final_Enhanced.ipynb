{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH7MZulOViNq"
      },
      "source": [
        "## CELL 1: Mount Google Drive (REQUIRED - DO THIS FIRST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hy66ImvViNq",
        "outputId": "7ac11376-2575-4992-8431-1a4f58f2568e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "print(\"Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MuxCMyxViNr"
      },
      "source": [
        "## CELL 2: Check GPU and Navigate to Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG-SEHqeViNr",
        "outputId": "0435ae8a-d0a0-4e6c-9dc8-e7655008e56b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Check GPU\n",
        "print(\"=\" * 50)\n",
        "print(\"GPU INFORMATION\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Navigate to project\n",
        "PROJECT_PATH = '/content/drive/MyDrive/HRF-Segmentation-Unet'\n",
        "CODE_PATH = os.path.join(PROJECT_PATH, 'code')\n",
        "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
        "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
        "\n",
        "# Create checkpoint directory if it doesn't exist\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"\\nProject Path: {PROJECT_PATH}\")\n",
        "print(f\"Code Path: {CODE_PATH}\")\n",
        "print(f\"Data Path: {DATA_PATH}\")\n",
        "print(f\"Checkpoint Path: {CHECKPOINT_PATH}\")\n",
        "\n",
        "# Verify files exist\n",
        "print(f\"\\nCode files in Google Drive:\")\n",
        "for file in os.listdir(CODE_PATH):\n",
        "    print(f\"  - {file}\")\n",
        "\n",
        "print(f\"\\nData folders:\")\n",
        "for folder in os.listdir(DATA_PATH):\n",
        "    print(f\"  - {folder}/\")\n",
        "    count = len(os.listdir(os.path.join(DATA_PATH, folder)))\n",
        "    print(f\"    ({count} files)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqiHA8NiViNr"
      },
      "source": [
        "## CELL 3: Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsoUKJ2vViNr",
        "outputId": "51bb76f6-889f-4564-d8ac-55113ade1758"
      },
      "outputs": [],
      "source": [
        "# Install required packages (Colab already has most pre-installed)\n",
        "!pip install -q opencv-python tqdm tifffile imagecodecs albumentations -U\n",
        "\n",
        "print(\"✓ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfC6Y52AViNs"
      },
      "source": [
        "## CELL 4: Import Your Code from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1V6MuiPViNs",
        "outputId": "98402f3f-41ae-46c4-b2b2-e6554ee8f82b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, CODE_PATH)\n",
        "\n",
        "# Import your code modules - UPDATED: using dataset_enhanced\n",
        "from dataset_enhanced import create_dataloaders\n",
        "from losses import get_loss_function\n",
        "from metrics import evaluate_batch, MetricsTracker\n",
        "from unet import UNet\n",
        "from train import Trainer\n",
        "\n",
        "print(\"✓ All modules imported successfully!\")\n",
        "print(f\"\\nAvailable modules:\")\n",
        "print(f\"  - dataset_enhanced \")\n",
        "print(f\"  - losses (loss functions)\")\n",
        "print(f\"  - metrics (evaluation metrics)\")\n",
        "print(f\"  - unet (U-Net model)\")\n",
        "print(f\"  - train (training framework)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wJx9FO3ViNs"
      },
      "source": [
        "## CELL 5: Verify Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "IVOnP_CqViNs",
        "outputId": "6b653546-b347-4af5-b722-cf57877964f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tifffile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_DIR = os.path.join(DATA_PATH, 'images')\n",
        "MASK_DIR = os.path.join(DATA_PATH, 'masks')\n",
        "\n",
        "# Count files\n",
        "image_files = sorted([f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff', '.tif'))])\n",
        "mask_files = sorted([f for f in os.listdir(MASK_DIR) if f.lower().endswith(('.tiff', '.tif', '.jpeg', '.jpg', '.png'))])\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"DATA VERIFICATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total images: {len(image_files)}\")\n",
        "print(f\"Total masks: {len(mask_files)}\")\n",
        "print(f\"\\nNOTE: Images loaded at original size!\")\n",
        "print(f\"NOTE: Using TIFFFILE for proper .ome.tiff handling\")\n",
        "\n",
        "if len(image_files) > 0 and len(mask_files) > 0:\n",
        "    # Load sample\n",
        "    sample_img_name = image_files[0]\n",
        "    sample_img_path = os.path.join(IMAGE_DIR, sample_img_name)\n",
        "\n",
        "    sample_img = cv2.imread(sample_img_path)\n",
        "    sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    print(f\"\\nSample Image (ORIGINAL SIZE):\")\n",
        "    print(f\"  Filename: {sample_img_name}\")\n",
        "    print(f\"  Shape: {sample_img.shape}\")\n",
        "    print(f\"  Dtype: {sample_img.dtype}\")\n",
        "    print(f\"  Range: [{sample_img.min()}, {sample_img.max()}]\")\n",
        "\n",
        "    # IMPROVED MASK FINDING - WITH TIFFFILE FOR SCIENTIFIC .OME.TIFF\n",
        "    print(f\"\\nFinding mask for: {sample_img_name}\")\n",
        "\n",
        "    # Generate all candidate mask names\n",
        "    candidates = [\n",
        "        sample_img_name.replace('.jpg', '_HRF.ome.tiff').replace('.jpeg', '_HRF.ome.tiff').replace('.png', '_HRF.ome.tiff'),\n",
        "        sample_img_name.replace('.jpg', '.tiff').replace('.jpeg', '.tiff').replace('.png', '.tiff'),\n",
        "        sample_img_name.replace('.jpg', '_mask.tiff').replace('.jpeg', '_mask.tiff').replace('.png', '_mask.tiff'),\n",
        "        sample_img_name.replace('.jpg', '_HRF.ome.tif').replace('.jpeg', '_HRF.ome.tif').replace('.png', '_HRF.ome.tif'),\n",
        "        sample_img_name.replace('.jpg', '.tif').replace('.jpeg', '.tif').replace('.png', '.tif'),\n",
        "        sample_img_name.replace('.jpg', '_mask.tif').replace('.jpeg', '_mask.tif').replace('.png', '_mask.tif'),\n",
        "    ]\n",
        "\n",
        "    sample_mask_path = None\n",
        "    sample_mask = None\n",
        "\n",
        "    for i, candidate in enumerate(candidates):\n",
        "        candidate_path = os.path.join(MASK_DIR, candidate)\n",
        "        if os.path.exists(candidate_path):\n",
        "            print(f\"  ✓ Found: {candidate}\")\n",
        "\n",
        "            # IMPORTANT: Use TIFFFILE for .ome.tiff files\n",
        "            # TIFFFILE properly handles scientific TIFF format with metadata\n",
        "            try:\n",
        "                sample_mask = tifffile.imread(candidate_path)\n",
        "                sample_mask_path = candidate_path\n",
        "                print(f\"    ✓ Successfully read with TIFFFILE\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"    ✗ Error reading file: {e}\")\n",
        "                continue\n",
        "        else:\n",
        "            print(f\"  ✗ Not found: {candidate}\")\n",
        "\n",
        "    if sample_mask is None:\n",
        "        print(f\"\\n⚠️ MASK NOT FOUND OR COULD NOT BE READ!\")\n",
        "        print(f\"Check that mask files exist and are in supported format (.tiff, .tif)\")\n",
        "    else:\n",
        "        # Handle multi-channel masks\n",
        "        if len(sample_mask.shape) == 3:\n",
        "            print(f\"  Note: Mask is multi-channel/multi-page (shape: {sample_mask.shape})\")\n",
        "            # Take first channel if multi-channel\n",
        "            sample_mask = sample_mask[0] if sample_mask.shape[0] < sample_mask.shape[1] else sample_mask[:, :, 0]\n",
        "            print(f\"        Using first channel (shape: {sample_mask.shape})\")\n",
        "\n",
        "        print(f\"\\nSample Mask:\")\n",
        "        print(f\"  Filename: {os.path.basename(sample_mask_path)}\")\n",
        "        print(f\"  Shape: {sample_mask.shape}\")\n",
        "        print(f\"  Dtype: {sample_mask.dtype}\")\n",
        "        print(f\"  Unique values: {np.unique(sample_mask)}\")\n",
        "        print(f\"  HRF pixels: {np.sum(sample_mask > 0)}\")\n",
        "        print(f\"  Note: Legend area in mask should be 0 (not marked as HRF)\")\n",
        "\n",
        "        # Binarize for training\n",
        "        sample_mask_binary = (sample_mask > 0).astype(np.float32)\n",
        "        if len(np.unique(sample_mask)) > 2:\n",
        "            print(f\"  Note: Mask has {len(np.unique(sample_mask))} unique values\")\n",
        "            print(f\"        Will be binarized during training (threshold=0)\")\n",
        "\n",
        "        # Visualize\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        axes[0].imshow(sample_img)\n",
        "        axes[0].set_title('OCT Image (Original Size)')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(sample_mask, cmap='gray')\n",
        "        axes[1].set_title('HRF Mask (from .ome.tiff)')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        overlay = sample_img.copy()\n",
        "        overlay[sample_mask_binary > 0] = [255, 0, 0]  # Red for HRF\n",
        "        axes[2].imshow(overlay)\n",
        "        axes[2].set_title('Overlay (Red = HRF, Legend = Background)')\n",
        "        axes[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\n✓ Data verification successful!\")\n",
        "else:\n",
        "    print(\"\\n⚠️ WARNING: No images or masks found!\")\n",
        "    print(\"Make sure you uploaded them to Google Drive correctly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQAM49DWViNs"
      },
      "source": [
        "## CELL 6: Create Data Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ZDBjanViNs",
        "outputId": "f3618292-d554-4325-84d2-9a4835e5c630"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_DIR = os.path.join(DATA_PATH, 'images')\n",
        "image_files = sorted([f for f in os.listdir(IMAGE_DIR) if f.endswith(('.jpg','.jpeg', '.png', '.tiff'))])\n",
        "\n",
        "# Create splits\n",
        "np.random.seed(42)\n",
        "all_files = image_files.copy()\n",
        "np.random.shuffle(all_files)\n",
        "\n",
        "n_total = len(all_files)\n",
        "n_train = int(n_total * 0.70)\n",
        "n_val = int(n_total * 0.15)\n",
        "\n",
        "train_files = all_files[:n_train]\n",
        "val_files = all_files[n_train:n_train + n_val]\n",
        "test_files = all_files[n_train + n_val:]\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DATA SPLIT\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total images: {n_total}\")\n",
        "print(f\"Training: {len(train_files)} ({100*len(train_files)/n_total:.1f}%)\")\n",
        "print(f\"Validation: {len(val_files)} ({100*len(val_files)/n_total:.1f}%)\")\n",
        "print(f\"Test: {len(test_files)} ({100*len(test_files)/n_total:.1f}%)\")\n",
        "\n",
        "print(\"\\n✓ Data split completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FuFArZvViNt"
      },
      "source": [
        "## CELL 7: Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZL8tTbpViNt",
        "outputId": "f9d1e339-84d6-4833-af78-ff74058d62a5"
      },
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "print(\"Creating data loaders...\")\n",
        "print(\"This may take a moment...\\n\")\n",
        "\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    data_dir=DATA_PATH,\n",
        "    train_files=train_files,\n",
        "    val_files=val_files,\n",
        "    test_files=test_files,\n",
        "    batch_size=4,  # Reduced for variable image sizes\n",
        "    num_workers=2,  # Colab works best with 2 workers\n",
        "    image_size=None,  # None = keep original size\n",
        "    apply_augmentation=True,  # ENABLED augmentation\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DATA LOADERS CREATED\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Test one batch\n",
        "images, masks = next(iter(train_loader))\n",
        "print(f\"\\nBatch shape (note: may vary due to original sizes):\")\n",
        "print(f\"  Images: {images.shape}\")\n",
        "print(f\"  Masks: {masks.shape}\")\n",
        "print(f\"\\n✓ Data loaders ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdrq0yZlViNt"
      },
      "source": [
        "## CELL 8: Setup Model and Training Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRNJdNmhViNt",
        "outputId": "d9a8e720-01c0-4f3c-e796-89a8f5073c8d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Create model\n",
        "print(\"\\nCreating U-Net model...\")\n",
        "model = UNet(\n",
        "    n_channels=3,\n",
        "    n_classes=1,\n",
        "    bilinear=False,\n",
        "    base_filters=64,\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model: U-Net\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Test forward pass\n",
        "test_input = torch.randn(2, 3, 512, 512).to(device)\n",
        "with torch.no_grad():\n",
        "    test_output = model(test_input)\n",
        "print(f\"\\nTest forward pass:\")\n",
        "print(f\"  Input shape: {test_input.shape}\")\n",
        "print(f\"  Output shape: {test_output.shape}\")\n",
        "\n",
        "# Loss function\n",
        "print(f\"\\nSetup loss function...\")\n",
        "loss_fn = get_loss_function(\n",
        "    'focal_tversky',\n",
        "    alpha=0.3,\n",
        "    beta=0.7,\n",
        "    gamma=4/3,\n",
        ")\n",
        "print(f\"Loss: Focal Tversky Loss (recommended for class imbalance)\")\n",
        "\n",
        "# Optimizer\n",
        "print(f\"\\nSetup optimizer...\")\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.001,\n",
        "    weight_decay=0.0001,\n",
        ")\n",
        "print(f\"Optimizer: Adam\")\n",
        "print(f\"Learning Rate: 0.001\")\n",
        "\n",
        "# Scheduler\n",
        "print(f\"\\nSetup scheduler...\")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        ")\n",
        "print(f\"Scheduler: ReduceLROnPlateau\")\n",
        "\n",
        "print(f\"\\n✓ All components ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAVX1Itttj7V",
        "outputId": "c5657bb2-be95-4479-98c2-9effe64daac4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# ========== LOAD CHECKPOINT (CELL 8.5 - NEW CELL) ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LOADING CHECKPOINT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/HRF-Segmentation-Unet/checkpoints/best_model.pth'\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"✓ Checkpoint found: {checkpoint_path}\")\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path,weights_only=False, map_location=device)\n",
        "\n",
        "    # Restore model weights\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    print(f\"✓ Model weights loaded from epoch {checkpoint['epoch']}\")\n",
        "\n",
        "    # Restore optimizer state\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(f\"✓ Optimizer state restored\")\n",
        "\n",
        "    # Restore scheduler state\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    print(f\"✓ Scheduler state restored\")\n",
        "\n",
        "    # Extract metadata\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Start from NEXT epoch\n",
        "\n",
        "    print(f\"\\n✓ Ready to resume training!\")\n",
        "    print(f\"  - Start epoch: {start_epoch}/100\")\n",
        "    print(f\"  - Remaining epochs: {100 - start_epoch}\")\n",
        "else:\n",
        "    print(f\"❌ Checkpoint not found at {checkpoint_path}\")\n",
        "    print(\"Starting fresh training from epoch 1\")\n",
        "    start_epoch = 1\n",
        "    best_dice = 0.0\n",
        "\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7TcU-g_ViNt"
      },
      "source": [
        "## CELL 9: Create Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cla748CRViNt",
        "outputId": "16a7bbd3-2c78-4441-a3b5-589edc750831"
      },
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "print(\"Creating trainer...\\n\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    checkpoint_dir=CHECKPOINT_PATH,\n",
        "    use_amp=True,  # Mixed precision for faster training\n",
        "    log_wandb=False,  # Set to True if you want to use W&B\n",
        ")\n",
        "\n",
        "print(f\"Trainer created successfully!\")\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"  Device: {device}\")\n",
        "print(f\"  Mixed Precision: True\")\n",
        "print(f\"  AUGMENTATION: Albumentations (Flip, Rotate, Brightness)\")\n",
        "print(f\"  Checkpoint Dir: {CHECKPOINT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbmxQMvgViNt"
      },
      "source": [
        "## CELL 10: Start Training (Main Training Cell) ⭐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78nFmVCpViNt",
        "outputId": "80b5d78b-6cb1-4eda-83b2-dc0c4f92c6c2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "CHECKPOINT_PATH = '/content/drive/MyDrive/HRF-Segmentation-Unet/checkpoints/'\n",
        "best_model_path = os.path.join(CHECKPOINT_PATH, 'best_model.pth')\n",
        "# MAIN TRAINING CELL\n",
        "print(\"=\"*60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTraining started at: {pd.Timestamp.now()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"Total epochs: 100\")\n",
        "print(f\"Batch size: 4\")\n",
        "print(f\"Images loaded at original size\")\n",
        "print(f\"\\nNote: Training will save checkpoints to Google Drive automatically.\")\n",
        "print(f\"Best model will be saved to: {os.path.join(CHECKPOINT_PATH, 'best_model.pth')}\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "\n",
        "# Train\n",
        "trainer.train(\n",
        "    num_epochs=100,\n",
        "    early_stopping_patience=25,\n",
        "    #resume_from=best_model_path,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Best Validation Dice: {trainer.best_val_dice:.4f}\")\n",
        "print(f\"\\nCheckpoints saved to: {CHECKPOINT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5vRGibMViNu"
      },
      "source": [
        "## CELL 11: Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9rm50i-ViNu",
        "outputId": "9d2cec78-64cf-40f2-e9b7-bafd1af5c388"
      },
      "outputs": [],
      "source": [
        "from metrics import evaluate_batch, MetricsTracker\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import jaccard_score, roc_curve, auc, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load best model\n",
        "checkpoint_path = os.path.join(CHECKPOINT_PATH, 'best_model.pth')\n",
        "checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded best model from: {checkpoint_path}\")\n",
        "print(f\"Best validation Dice: {checkpoint['metrics']['dice']:.4f}\\n\")\n",
        "\n",
        "# Evaluate on test set\n",
        "metrics_tracker = MetricsTracker()\n",
        "all_targets = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, masks in tqdm(test_loader, desc='Evaluating on test set'):\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        batch_metrics = evaluate_batch(outputs, masks)\n",
        "        metrics_tracker.update(batch_metrics)\n",
        "\n",
        "        # Store for sklearn metrics\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        all_probs.append(probs.cpu().numpy().flatten())\n",
        "        all_targets.append(masks.cpu().numpy().flatten())\n",
        "\n",
        "# Get results\n",
        "results = metrics_tracker.get_average()\n",
        "std_results = metrics_tracker.get_std()\n",
        "\n",
        "# Calculate global metrics\n",
        "print(\"Calculating global metrics (Jaccard, ROC, Confusion Matrix)...\")\n",
        "all_targets_np = np.concatenate(all_targets)\n",
        "all_probs_np = np.concatenate(all_probs)\n",
        "all_preds_np = (all_probs_np > 0.5).astype(int)\n",
        "\n",
        "# Jaccard\n",
        "jaccard = jaccard_score(all_targets_np, all_preds_np)\n",
        "\n",
        "# ROC and AUC\n",
        "fpr, tpr, _ = roc_curve(all_targets_np, all_probs_np)\n",
        "auc_score = auc(fpr, tpr)\n",
        "\n",
        "# Confusion Matrix\n",
        "tn, fp, fn, tp = confusion_matrix(all_targets_np, all_preds_np).ravel()\n",
        "\n",
        "# Save Results to File for Average Calculation later\n",
        "metrics_file = os.path.join(CHECKPOINT_PATH, 'test_metrics_history.csv')\n",
        "\n",
        "new_row = {\n",
        "    'timestamp': pd.Timestamp.now(),\n",
        "    'dice': results['dice'],\n",
        "    'dice_std': std_results['dice'],\n",
        "    'iou': results['iou'],\n",
        "    'iou_std': std_results['iou'],\n",
        "    'precision': results['precision'],\n",
        "    'precision_std': std_results['precision'],\n",
        "    'recall': results['recall'],\n",
        "    'recall_std': std_results['recall'],\n",
        "    'f1': results['f1'],\n",
        "    'f1_std': std_results['f1'],\n",
        "    'specificity': results['specificity'],\n",
        "    'specificity_std': std_results['specificity'],\n",
        "    'jaccard': jaccard,\n",
        "    'auc': auc_score,\n",
        "    'tp': tp,\n",
        "    'tn': tn,\n",
        "    'fp': fp,\n",
        "    'fn': fn\n",
        "}\n",
        "\n",
        "# Append to CSV\n",
        "if os.path.exists(metrics_file):\n",
        "    # Check if we need to update columns in case existing file is old\n",
        "    df = pd.read_csv(metrics_file)\n",
        "    new_df = pd.DataFrame([new_row])\n",
        "    df = pd.concat([df, new_df], ignore_index=True)\n",
        "else:\n",
        "    df = pd.DataFrame([new_row])\n",
        "\n",
        "df.to_csv(metrics_file, index=False)\n",
        "print(f\"Results appended to: {metrics_file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST SET RESULTS\")\n",
        "print(\"=\"*60)\n",
        "for metric, value in results.items():\n",
        "    print(f\"{metric.capitalize():15s}: {value:.4f} ± {std_results[metric]:.4f}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Jaccard':15s}: {jaccard:.4f}\")\n",
        "print(f\"{'AUC':15s}: {auc_score:.4f}\")\n",
        "print(f\"{'Confusion Matrix':15s}: TP={tp}, TN={tn}, FP={fp}, FN={fn}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VcdcAEiViNu"
      },
      "source": [
        "## CELL 12: Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bKspdGQoViNu",
        "outputId": "a22b20fc-8482-41eb-d821-3e46fa63f426"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "# Visualize 5 Random Samples\n",
        "num_samples_to_visualize = 5\n",
        "dataset = test_loader.dataset\n",
        "dataset_len = len(dataset)\n",
        "\n",
        "# Select random indices\n",
        "if dataset_len < num_samples_to_visualize:\n",
        "    indices = list(range(dataset_len))\n",
        "    print(f\"Warning: Dataset smaller than {num_samples_to_visualize}, evaluating all {dataset_len} samples.\")\n",
        "else:\n",
        "    indices = random.sample(range(dataset_len), num_samples_to_visualize)\n",
        "\n",
        "print(f\"Visualizing samples at indices: {indices}\")\n",
        "\n",
        "# Collect samples\n",
        "selected_images = []\n",
        "selected_masks = []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx in indices:\n",
        "        # dataset[idx] returns (image, mask) tuple of tensors\n",
        "        img_tensor, mask_tensor = dataset[idx]\n",
        "        selected_images.append(img_tensor)\n",
        "        selected_masks.append(mask_tensor)\n",
        "\n",
        "    # Stack into batches\n",
        "    batch_images = torch.stack(selected_images).to(device)\n",
        "    batch_masks = torch.stack(selected_masks).cpu().numpy()\n",
        "\n",
        "    # Predict\n",
        "    outputs = model(batch_images)\n",
        "    predictions = torch.sigmoid(outputs) > 0.5\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "# Plotting and Saving Individual Files\n",
        "num_samples = len(indices)\n",
        "print(\"Saving individual prediction images...\")\n",
        "\n",
        "for i in range(num_samples):\n",
        "    # Denormalize image\n",
        "    img_np = batch_images[i].cpu().numpy().transpose(1, 2, 0)\n",
        "    img_np = img_np / img_np.max() if img_np.max() > 0 else img_np  # Normalize to 0-1\n",
        "    img_np = np.clip(img_np, 0, 1)\n",
        "\n",
        "    mask_np = batch_masks[i, 0]\n",
        "    pred_np = predictions[i, 0]\n",
        "\n",
        "    # Create a separate figure for each sample\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "    axes[0].imshow(img_np)\n",
        "    axes[0].set_title(f'Sample {indices[i]}: Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(mask_np, cmap='gray')\n",
        "    axes[1].set_title(f'Sample {indices[i]}: Ground Truth')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(pred_np, cmap='gray')\n",
        "    axes[2].set_title(f'Sample {indices[i]}: Prediction')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    filename = f'prediction_sample_{indices[i]}.png'\n",
        "    save_path = os.path.join(CHECKPOINT_PATH, filename)\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show() # Display inline as well\n",
        "    plt.close(fig) # Close to free memory\n",
        "    print(f\"Saved {filename}\")\n",
        "\n",
        "# Visualize ROC and Confusion Matrix (from Cell 11 calculated metrics)\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# ROC Curve\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.set_title('Receiver Operating Characteristic (ROC)')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = np.array([[tn, fp], [fn, tp]])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "ax2.set_title('Confusion Matrix')\n",
        "ax2.set_ylabel('Actual')\n",
        "ax2.set_xlabel('Predicted')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_PATH, 'metrics_visualization.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualizations saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XLh4iSxViNu"
      },
      "source": [
        "## CELL 13: Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOWfoicoViNu",
        "outputId": "acde9ec9-fc53-477d-a298-7851b23a0198"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RESULTS SAVED TO GOOGLE DRIVE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nCheckpoint directory: {CHECKPOINT_PATH}\")\n",
        "print(f\"\\nSaved files:\")\n",
        "for file in os.listdir(CHECKPOINT_PATH):\n",
        "    file_size = os.path.getsize(os.path.join(CHECKPOINT_PATH, file)) / 1e6\n",
        "    print(f\"  - {file} ({file_size:.1f} MB)\")\n",
        "\n",
        "print(f\"\\n✓ All results automatically saved to your Google Drive!\")\n",
        "print(f\"\\nYou can download them from:\")\n",
        "print(f\"Google Drive → HRF-Segmentation-Unet → checkpoints\")\n",
        "print(f\"\\nKey files:\")\n",
        "print(f\"  - best_model.pth (Your trained model - USE THIS!)\")\n",
        "print(f\"  - latest_model.pth (Last checkpoint)\")\n",
        "print(f\"  - predictions.png (Visual results)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
